"""
LAML: Lagrangian Action Minimization Learning
==============================================

ì™„ì „íˆ ìƒˆë¡œìš´ í•™ìŠµ íŒ¨ëŸ¬ë‹¤ì„ êµ¬í˜„

í•µì‹¬ ì•„ì´ë””ì–´:
1. ë°ì´í„° â†’ ìµœì¢… ê°€ì¤‘ì¹˜ ì˜ˆì¸¡ (ë©”íƒ€ ì˜ˆì¸¡)
2. ì‹œì‘ â†’ ë ìµœì  ê¶¤ì  ê³„ì‚° (BVP)
3. ìµœì†Œ ì‘ìš© ì›ë¦¬ ë§Œì¡± ì—¬ë¶€ ê²€ì¦
4. ë¶ˆë§Œì¡± ì‹œ íƒìƒ‰ ë° ë³´ì •
5. ê°•í™”í•™ìŠµì‹ ëœë¤ì„±ê³¼ ìê¸°í™•ì‹  ì¡°ì ˆ
"""

import numpy as np
import matplotlib.pyplot as plt
from typing import Tuple, Dict
import time


class LightweightNN:
    """ì´ˆê²½ëŸ‰ ì‹ ê²½ë§ (4â†’6â†’1)"""

    def __init__(self, seed=None):
        if seed:
            np.random.seed(seed)

        # ì‘ì€ ê°€ì¤‘ì¹˜ë¡œ ì´ˆê¸°í™”
        self.W1 = np.random.randn(4, 6) * 0.1
        self.b1 = np.zeros(6)
        self.W2 = np.random.randn(6, 1) * 0.1
        self.b2 = np.zeros(1)

    def forward(self, X):
        """ìˆœì „íŒŒ: ReLU í™œì„±í™”"""
        self.X = X
        self.z1 = X @ self.W1 + self.b1
        self.a1 = np.maximum(0, self.z1)
        self.z2 = self.a1 @ self.W2 + self.b2
        return self.z2

    def loss(self, X, y):
        """MSE ì†ì‹¤"""
        pred = self.forward(X)
        return np.mean((pred - y) ** 2)

    def get_weights(self):
        """ëª¨ë“  ê°€ì¤‘ì¹˜ë¥¼ 1D ë²¡í„°ë¡œ"""
        return np.concatenate([
            self.W1.flatten(), self.b1,
            self.W2.flatten(), self.b2
        ])

    def set_weights(self, w):
        """1D ë²¡í„°ì—ì„œ ê°€ì¤‘ì¹˜ ë³µì›"""
        self.W1 = w[:24].reshape(4, 6)
        self.b1 = w[24:30]
        self.W2 = w[30:36].reshape(6, 1)
        self.b2 = w[36:37]

    def gradient(self, X, y):
        """ì—­ì „íŒŒë¡œ ê·¸ë˜ë””ì–¸íŠ¸ ê³„ì‚°"""
        m = len(X)
        pred = self.forward(X)

        # ì—­ì „íŒŒ
        dz2 = 2 * (pred - y) / m
        dW2 = self.a1.T @ dz2
        db2 = np.sum(dz2, axis=0)

        da1 = dz2 @ self.W2.T
        dz1 = da1 * (self.z1 > 0)
        dW1 = X.T @ dz1
        db1 = np.sum(dz1, axis=0)

        return np.concatenate([
            dW1.flatten(), db1,
            dW2.flatten(), db2
        ])


class MetaPredictor:
    """
    ë©”íƒ€ ì˜ˆì¸¡ê¸°: ë°ì´í„° â†’ ìµœì¢… ê°€ì¤‘ì¹˜ ì˜ˆì¸¡

    ì‹¤ì œë¡œëŠ” ë§ì€ í•™ìŠµ ê²½í—˜ìœ¼ë¡œë¶€í„° í•™ìŠµëœ ëª¨ë¸ì´ì–´ì•¼ í•˜ì§€ë§Œ,
    ì—¬ê¸°ì„œëŠ” ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹± ì‚¬ìš©
    """

    def predict(self, X, y, current_w, network):
        """
        ë°ì´í„° íŠ¹ì„±ìœ¼ë¡œë¶€í„° ìµœì¢… ê°€ì¤‘ì¹˜ë¥¼ ì˜ˆì¸¡

        ì „ëµ:
        1. í˜„ì¬ gradient ë°©í–¥ ê³„ì‚°
        2. ë°ì´í„° ë¶„ì‚°ì„ ê³ ë ¤í•œ step size
        3. ì•½ê°„ì˜ ëœë¤ íƒìƒ‰
        """
        # Gradient ë°©í–¥
        grad = network.gradient(X, y)

        # ë°ì´í„° íŠ¹ì„± ê¸°ë°˜ ìŠ¤ì¼€ì¼
        y_std = np.std(y)
        scale = 2.0 * (1 + y_std)

        # ì˜ˆì¸¡: í˜„ì¬ + (gradient ë°˜ëŒ€ ë°©í–¥) + íƒìƒ‰
        predicted = current_w - scale * grad
        predicted += np.random.randn(len(current_w)) * 0.3

        return predicted


class BVPSolver:
    """
    ê²½ê³„ê°’ ë¬¸ì œ(BVP) ì†”ë²„: Î¸â‚€ â†’ Î¸_T ìµœì  ê¶¤ì  ê³„ì‚°

    ì´ìƒì ìœ¼ë¡œëŠ” Euler-Lagrange ë°©ì •ì‹ì„ í’€ì–´ì•¼ í•˜ì§€ë§Œ,
    ì—¬ê¸°ì„œëŠ” smoothstep ë³´ê°„ ì‚¬ìš© (ê³„ì‚° íš¨ìœ¨ì„±)
    """

    def solve(self, theta_0, theta_T, steps=10):
        """Smoothstep ë³´ê°„ìœ¼ë¡œ ë¶€ë“œëŸ¬ìš´ ê¶¤ì  ìƒì„±"""
        trajectory = []

        for i in range(steps):
            t = i / (steps - 1)
            # Smoothstep: 3tÂ² - 2tÂ³
            smooth = 3 * t**2 - 2 * t**3
            theta_t = theta_0 + smooth * (theta_T - theta_0)
            trajectory.append(theta_t)

        return np.array(trajectory)


class ActionCalculator:
    """
    ì‘ìš©(Action) ê³„ì‚°ê¸°

    S = âˆ«[Â½||Î¸Ì‡||Â² + Î»L(Î¸)] dt

    - ìš´ë™ ì—ë„ˆì§€: Â½||Î¸Ì‡||Â²  (ë³€í™”ì˜ ë¹ ë¥´ê¸°)
    - í¬í…ì…œ: Î»L(Î¸)        (ì†ì‹¤ í•¨ìˆ˜)
    """

    def __init__(self, network, X, y, lambda_loss=1.0):
        self.net = network
        self.X = X
        self.y = y
        self.lambda_loss = lambda_loss

    def compute(self, trajectory):
        """ê¶¤ì ì„ ë”°ë¼ ì‘ìš© ì ë¶„"""
        action = 0.0

        for i in range(len(trajectory) - 1):
            theta_t = trajectory[i]
            theta_next = trajectory[i + 1]

            # ì†ë„: Î¸Ì‡
            velocity = theta_next - theta_t
            kinetic = 0.5 * np.sum(velocity ** 2)

            # ì†ì‹¤
            self.net.set_weights(theta_t)
            loss = self.net.loss(self.X, self.y)
            potential = self.lambda_loss * loss

            # Lagrangian
            action += kinetic + potential

        return action / len(trajectory)


class LAMLOptimizer:
    """
    LAML ìµœì í™”ê¸°: ìƒˆë¡œìš´ í•™ìŠµ íŒ¨ëŸ¬ë‹¤ì„

    ì•Œê³ ë¦¬ì¦˜:
    1. ë°ì´í„° â†’ ìµœì¢… ê°€ì¤‘ì¹˜ ì˜ˆì¸¡
    2. ì‹œì‘ â†’ ë ê¶¤ì  ê³„ì‚°
    3. Action ê²€ì¦
    4. ë¶ˆë§Œì¡± â†’ íƒìƒ‰ & ë³´ì •
    5. ë§Œì¡± â†’ ì—…ë°ì´íŠ¸
    6. ëœë¤ì„± + ìê¸°í™•ì‹  ì¡°ì ˆ
    """

    def __init__(self, network,
                 action_threshold=0.5,
                 learning_rate=0.1,
                 explore_samples=8):
        self.net = network
        self.action_threshold = action_threshold
        self.lr = learning_rate
        self.explore_samples = explore_samples

        self.meta_predictor = MetaPredictor()
        self.bvp_solver = BVPSolver()

        # ì¶”ì 
        self.history = {
            'loss': [],
            'action': [],
            'confidence': [],
            'accept_rate': []
        }
        self.confidence = 1.0  # ìê¸°í™•ì‹ 
        self.accepts = 0
        self.rejects = 0

    def train(self, X, y, max_iters=100, verbose=True):
        """LAML í•™ìŠµ ë£¨í”„"""
        start = time.time()
        action_calc = ActionCalculator(self.net, X, y)

        for it in range(max_iters):
            # 1. ë©”íƒ€ ì˜ˆì¸¡: ë°ì´í„° â†’ ìµœì¢… ê°€ì¤‘ì¹˜
            theta_0 = self.net.get_weights()
            theta_pred = self.meta_predictor.predict(X, y, theta_0, self.net)

            # 2. BVP: ì‹œì‘ â†’ ë ê¶¤ì 
            traj = self.bvp_solver.solve(theta_0, theta_pred, steps=10)

            # 3. Action ê³„ì‚°
            action = action_calc.compute(traj)
            loss_before = self.net.loss(X, y)

            # 4. Actionì´ ë„ˆë¬´ í¬ë©´ íƒìƒ‰ & ë³´ì •
            if action > self.action_threshold:
                theta_pred = self._explore_alternatives(
                    X, y, theta_0, theta_pred, action_calc
                )
                traj = self.bvp_solver.solve(theta_0, theta_pred, steps=10)
                action = action_calc.compute(traj)
                self.rejects += 1
            else:
                self.accepts += 1

            # 5. ê¶¤ì ì„ ë”°ë¼ ì—…ë°ì´íŠ¸
            step_size = self.lr * self.confidence
            direction = traj[1] - theta_0

            # ëœë¤ íƒìƒ‰ ì¶”ê°€ (ê°•í™”í•™ìŠµ íš¨ê³¼)
            noise = np.random.randn(len(theta_0)) * 0.02 * self.confidence
            theta_new = theta_0 + step_size * direction + noise

            self.net.set_weights(theta_new)
            loss_after = self.net.loss(X, y)

            # 6. ìê¸°í™•ì‹  ì¡°ì ˆ
            if loss_after < loss_before:
                self.confidence = min(1.0, self.confidence * 1.05)
            else:
                self.confidence *= 0.95
                self.confidence = max(0.1, self.confidence)

            # ì¶”ì 
            self.history['loss'].append(loss_after)
            self.history['action'].append(action)
            self.history['confidence'].append(self.confidence)
            accept_rate = self.accepts / (self.accepts + self.rejects + 1e-8)
            self.history['accept_rate'].append(accept_rate)

            if verbose and it % 10 == 0:
                print(f"[{it:3d}] Loss: {loss_after:.5f} | "
                      f"Action: {action:.4f} | "
                      f"Conf: {self.confidence:.3f} | "
                      f"Accept: {accept_rate:.2%}")

            # ì¡°ê¸° ì¢…ë£Œ
            if action < self.action_threshold and loss_after < 0.01:
                if verbose:
                    print(f"\nâœ“ Converged at iteration {it}")
                break

        elapsed = time.time() - start
        return {
            'final_loss': self.history['loss'][-1],
            'iterations': len(self.history['loss']),
            'time': elapsed
        }

    def _explore_alternatives(self, X, y, theta_0, theta_current, action_calc):
        """
        Actionì´ ë†’ì„ ë•Œ ëŒ€ì•ˆ íƒìƒ‰
        ê°•í™”í•™ìŠµì‹ ëœë¤ íƒìƒ‰
        """
        best_theta = theta_current
        best_action = float('inf')

        for _ in range(self.explore_samples):
            # ëœë¤ ì„­ë™
            noise = np.random.randn(len(theta_current)) * 0.3 * self.confidence
            candidate = theta_current + noise

            # í‰ê°€
            traj = self.bvp_solver.solve(theta_0, candidate, steps=10)
            action = action_calc.compute(traj)

            if action < best_action:
                best_action = action
                best_theta = candidate

        return best_theta


class SGDOptimizer:
    """ë¹„êµë¥¼ ìœ„í•œ í‘œì¤€ SGD"""

    def __init__(self, network, learning_rate=0.1):
        self.net = network
        self.lr = learning_rate
        self.history = {'loss': []}

    def train(self, X, y, max_iters=100, verbose=False):
        """í‘œì¤€ gradient descent"""
        start = time.time()

        for it in range(max_iters):
            grad = self.net.gradient(X, y)
            w = self.net.get_weights()
            w -= self.lr * grad
            self.net.set_weights(w)

            loss = self.net.loss(X, y)
            self.history['loss'].append(loss)

            if verbose and it % 10 == 0:
                print(f"[{it:3d}] Loss: {loss:.5f}")

            if loss < 0.01:
                break

        elapsed = time.time() - start
        return {
            'final_loss': self.history['loss'][-1],
            'iterations': len(self.history['loss']),
            'time': elapsed
        }


def make_dataset(name='nonlinear', n=100):
    """í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ìƒì„±"""
    np.random.seed(42)
    X = np.random.randn(n, 4)

    if name == 'linear':
        y = (X @ [1, -0.5, 0.3, 0.8]).reshape(-1, 1)
    elif name == 'nonlinear':
        y = (np.sin(X[:, 0]) + np.cos(X[:, 1]) * X[:, 2]).reshape(-1, 1)
    elif name == 'xor':
        y = ((X[:, 0] > 0) ^ (X[:, 1] > 0)).astype(float).reshape(-1, 1)

    # ì •ê·œí™”
    X = (X - X.mean(0)) / (X.std(0) + 1e-8)
    y = (y - y.mean()) / (y.std() + 1e-8)

    return X, y


def run_experiment(dataset_name='nonlinear'):
    """ì‹¤í—˜ ì‹¤í–‰: LAML vs SGD"""
    print(f"\n{'='*70}")
    print(f"ì‹¤í—˜: {dataset_name.upper()} ë°ì´í„°ì…‹")
    print(f"{'='*70}\n")

    X, y = make_dataset(dataset_name, n=100)
    print(f"ë°ì´í„°: X={X.shape}, y={y.shape}\n")

    # LAML
    print("1ï¸âƒ£  LAML (Lagrangian Action Minimization Learning)")
    print("-" * 70)
    net_laml = LightweightNN(seed=42)
    opt_laml = LAMLOptimizer(net_laml, action_threshold=0.5, learning_rate=0.1)
    result_laml = opt_laml.train(X, y, max_iters=100, verbose=True)

    # SGD
    print(f"\n2ï¸âƒ£  Standard SGD")
    print("-" * 70)
    net_sgd = LightweightNN(seed=42)
    opt_sgd = SGDOptimizer(net_sgd, learning_rate=0.1)
    result_sgd = opt_sgd.train(X, y, max_iters=100, verbose=True)

    # ë¹„êµ
    print(f"\n{'='*70}")
    print("ğŸ“Š ê²°ê³¼ ë¹„êµ")
    print(f"{'='*70}")
    print(f"{'ì§€í‘œ':<25} {'LAML':>20} {'SGD':>20}")
    print("-" * 70)
    print(f"{'ìµœì¢… ì†ì‹¤':<25} {result_laml['final_loss']:>20.6f} {result_sgd['final_loss']:>20.6f}")
    print(f"{'ìˆ˜ë ´ ë°˜ë³µ íšŸìˆ˜':<25} {result_laml['iterations']:>20d} {result_sgd['iterations']:>20d}")
    print(f"{'í•™ìŠµ ì‹œê°„ (ì´ˆ)':<25} {result_laml['time']:>20.4f} {result_sgd['time']:>20.4f}")

    improvement = (result_sgd['final_loss'] - result_laml['final_loss']) / result_sgd['final_loss'] * 100
    print(f"{'ì†ì‹¤ ê°œì„ ìœ¨ (%)':<25} {improvement:>20.2f}")
    print("="*70)

    return {
        'laml': result_laml,
        'sgd': result_sgd,
        'laml_opt': opt_laml,
        'sgd_opt': opt_sgd,
        'dataset': dataset_name
    }


def plot_comparison(results):
    """ê²°ê³¼ ì‹œê°í™”"""
    laml_opt = results['laml_opt']
    sgd_opt = results['sgd_opt']
    dataset = results['dataset']

    fig, axes = plt.subplots(2, 2, figsize=(15, 10))
    fig.suptitle(f'LAML vs SGD: {dataset.upper()} Dataset',
                 fontsize=16, fontweight='bold')

    # 1. ì†ì‹¤ ê³¡ì„ 
    ax = axes[0, 0]
    ax.plot(laml_opt.history['loss'], 'b-', label='LAML', linewidth=2, alpha=0.8)
    ax.plot(sgd_opt.history['loss'], 'r--', label='SGD', linewidth=2, alpha=0.8)
    ax.set_xlabel('Iteration', fontsize=12)
    ax.set_ylabel('Loss', fontsize=12)
    ax.set_title('í•™ìŠµ ê³¡ì„ ', fontsize=14, fontweight='bold')
    ax.legend(fontsize=11)
    ax.grid(True, alpha=0.3)
    ax.set_yscale('log')

    # 2. Action (LAMLë§Œ)
    ax = axes[0, 1]
    ax.plot(laml_opt.history['action'], 'g-', linewidth=2, alpha=0.8)
    ax.axhline(y=0.5, color='red', linestyle='--', linewidth=2, label='Threshold')
    ax.set_xlabel('Iteration', fontsize=12)
    ax.set_ylabel('Action S', fontsize=12)
    ax.set_title('ì‘ìš© í•¨ìˆ˜ (LAML)', fontsize=14, fontweight='bold')
    ax.legend(fontsize=11)
    ax.grid(True, alpha=0.3)

    # 3. ìê¸°í™•ì‹ 
    ax = axes[1, 0]
    ax.plot(laml_opt.history['confidence'], 'm-', linewidth=2, alpha=0.8)
    ax.set_xlabel('Iteration', fontsize=12)
    ax.set_ylabel('Confidence', fontsize=12)
    ax.set_title('ìê¸°í™•ì‹  ë³€í™” (LAML)', fontsize=14, fontweight='bold')
    ax.grid(True, alpha=0.3)
    ax.set_ylim([0, 1.1])

    # 4. ìˆ˜ë½ë¥ 
    ax = axes[1, 1]
    ax.plot(laml_opt.history['accept_rate'], 'c-', linewidth=2, alpha=0.8)
    ax.set_xlabel('Iteration', fontsize=12)
    ax.set_ylabel('Accept Rate', fontsize=12)
    ax.set_title('ì˜ˆì¸¡ ìˆ˜ë½ë¥  (LAML)', fontsize=14, fontweight='bold')
    ax.grid(True, alpha=0.3)
    ax.set_ylim([0, 1.1])

    plt.tight_layout()

    filename = f'/Users/say/Documents/GitHub/ai/laml_{dataset}_results.png'
    plt.savefig(filename, dpi=300, bbox_inches='tight')
    print(f"\nâœ… ì‹œê°í™” ì €ì¥: {filename}")

    return fig


if __name__ == "__main__":
    print("\n" + "="*70)
    print("ğŸš€ LAML: Lagrangian Action Minimization Learning")
    print("   ë¬¼ë¦¬í•™ì—ì„œ ì˜ê°ì„ ë°›ì€ ì™„ì „íˆ ìƒˆë¡œìš´ í•™ìŠµ íŒ¨ëŸ¬ë‹¤ì„")
    print("="*70)

    # ì—¬ëŸ¬ ë°ì´í„°ì…‹ì—ì„œ ì‹¤í—˜
    datasets = ['linear', 'nonlinear', 'xor']
    all_results = {}

    for ds in datasets:
        result = run_experiment(ds)
        all_results[ds] = result
        plot_comparison(result)

    # ìµœì¢… ìš”ì•½
    print(f"\n{'='*70}")
    print("ğŸ¯ ì „ì²´ ìš”ì•½")
    print(f"{'='*70}")

    for ds, res in all_results.items():
        laml_loss = res['laml']['final_loss']
        sgd_loss = res['sgd']['final_loss']
        improvement = (sgd_loss - laml_loss) / sgd_loss * 100

        if improvement > 0:
            status = "âœ… LAML ìŠ¹ë¦¬"
        else:
            status = "âŒ SGD ìŠ¹ë¦¬"

        print(f"{ds.upper():12s} | {status:15s} | ê°œì„ : {improvement:+.2f}%")

    print("\n" + "="*70)
    print("âœ… ì‹¤í—˜ ì™„ë£Œ!")
    print("="*70 + "\n")

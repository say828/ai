# ULTIMATE v1.2 ì‹¤í—˜ ë¶„ì„

**ë‚ ì§œ**: 2026-01-03
**ê²°ê³¼**: v1.2ê°€ ì˜¬ë°”ë¥¸ ë°©í–¥ì„ì„ í™•ì¸ (Nonlinear +56.59%)

---

## ì‹¤í—˜ ê²°ê³¼

| Dataset | v1.0 | v1.2 | ë³€í™” | ìƒíƒœ |
|---------|------|------|------|------|
| Linear | 0.33446 | 0.48814 | **-45.95%** âŒ |
| Nonlinear | 3.22825 | 1.40153 | **+56.59%** âœ… |
| XOR | 0.15917 | 0.16452 | **-3.36%** âŒ |

**í‰ê· **: +2.43% (ëœë¤ì„±ìœ¼ë¡œ ì¸í•œ variance ì¡´ì¬)

---

## v1.2ì˜ í•µì‹¬ ê°œì„ ì‚¬í•­

### 1. Adaptive Primitive â†’ Adam-like

**ì´ì „ (v1.0)**:
```python
class AdaptiveStep:
    # RMSprop-like: 2ì°¨ momentë§Œ ì‚¬ìš©
    self.sum_squared_grad += grad ** 2
    adapted_lr = lr / (sqrt(sum_squared_grad) + epsilon)
    return -adapted_lr * grad
```

**ê°œì„  (v1.2)**:
```python
class AdaptiveStep:
    # Adam-like: 1ì°¨ + 2ì°¨ moment ëª¨ë‘ ì‚¬ìš©
    self.m = beta1 * m + (1-beta1) * grad        # 1st moment (momentum)
    self.v = beta2 * v + (1-beta2) * grad^2      # 2nd moment (RMSprop)

    # Bias correction
    m_hat = m / (1 - beta1^t)
    v_hat = v / (1 - beta2^t)

    # Adam update
    adapted_lr = lr / (sqrt(v_hat) + epsilon)
    return -adapted_lr * m_hat
```

**ì°¨ì´ì **:
- v1.0: ë‹¨ìˆœ RMSprop (ì ì‘ì  LRë§Œ)
- v1.2: Adam (momentum + ì ì‘ì  LR + bias correction)

### 2. PathSampling â†’ 20 samples

**ì´ì „ (v1.0)**: n_samples = 5 (ë„ˆë¬´ ì ìŒ)
**ê°œì„  (v1.2)**: n_samples = 20 (4ë°° ì¦ê°€)

**íš¨ê³¼**:
- ë” ë§ì€ ê²½ë¡œ íƒìƒ‰
- ë” ì •í™•í•œ path integral ê·¼ì‚¬
- ë” ì•ˆì •ì ì¸ ë°©í–¥ ì„ íƒ

### 3. v1.0ì˜ ì„±ê³µ ìš”ì†Œ ìœ ì§€

**ìœ ì§€ì‚¬í•­**:
- âŒ Winner-take-all ê°•ì œ ì•ˆí•¨ (v1.1ì—ì„œ ì‹¤íŒ¨)
- âŒ Primitive LR íŠœë‹ ì•ˆí•¨ (v1.1ì—ì„œ ì‹¤íŒ¨)
- âœ… ìì—°ìŠ¤ëŸ¬ìš´ soft winner-take-all
- âœ… ê· ì¼í•œ LR (ëª¨ë‘ 0.01)

---

## í•µì‹¬ ë°œê²¬: Adaptiveì˜ ìŠ¹ë¦¬!

### Nonlinear ë°ì´í„°ì…‹ (ê°€ì¥ ì¤‘ìš”)

#### v1.0 (ë‚˜ì¨):
```
GradientDescent: 71.37% âŒ (ì˜ëª»ëœ ì„ íƒ!)
ParticleSwarm: 17.22%
MultiScale: 5.31%
```
â†’ ë‹¨ìˆœ GDì— ì˜ì¡´ â†’ ì„±ëŠ¥ 3.23

#### v1.2 (ì¢‹ìŒ):
```
Adaptive: 56.49% âœ… (ì˜¬ë°”ë¥¸ ì„ íƒ!)
ActionGuided: 26.25%
Momentum: 10.21%
```
â†’ Adam-like Adaptive ì‚¬ìš© â†’ ì„±ëŠ¥ 1.40 (**56.59% ê°œì„ !**)

**í†µì°°**:
1. v1.0ë„ Adaptiveë¥¼ ê°€ì§€ê³  ìˆì—ˆì§€ë§Œ **ì•½í–ˆìŒ** (RMSprop ìˆ˜ì¤€)
2. v1.2ì—ì„œ Adaptiveë¥¼ **ê°•í™”** (Adam ìˆ˜ì¤€)
3. Policy networkê°€ ê°•í™”ëœ Adaptiveë¥¼ **ì„ íƒ**
4. ê²°ê³¼ì ìœ¼ë¡œ **ëŒ€í­ ê°œì„ **

---

## ì™œ Linearì™€ XORì€ ì•…í™”?

### ëœë¤ì„±ì˜ ì˜í–¥

**ì›ì¸**:
1. Policy network ì´ˆê¸°í™” ëœë¤
2. Primitive ë‚´ë¶€ ëœë¤ì„± (ParticleSwarm, StochasticJump, PathSampling)
3. ê°™ì€ ì½”ë“œì—¬ë„ ë‹¤ë¥¸ ì „ëµ í•™ìŠµ ê°€ëŠ¥

**ì¦ê±°**:

#### Linear ë°ì´í„°ì…‹
- v1.0: ActionGuided 28%, PathSampling 27%, StochJump 24% (ë¶„ì‚°)
- v1.2: GradientDescent 80% (ì§‘ì¤‘)
  â†’ v1.2ê°€ GDì— ê³¼ë„í•˜ê²Œ ì˜ì¡´ (unlucky initialization)

#### XOR ë°ì´í„°ì…‹
- v1.0: BestAttractor 58%, Adaptive 32%
- v1.2: ActionGuided 49%, Momentum 26%, MultiScale 7% (ë¶„ì‚°)
  â†’ v1.2ê°€ ëª…í™•í•œ ì „ëµ ëª» ì°¾ìŒ (unlucky initialization)

**í•´ê²°ì±…**: ì—¬ëŸ¬ ë²ˆ ì‹¤í–‰ í›„ í‰ê·  (ë˜ëŠ” pre-trainingìœ¼ë¡œ ì´ˆê¸°í™” ê°œì„ )

---

## ì§„ì§œ ì„±ê³µ: Nonlinearì˜ 56.59% ê°œì„ 

### ì™œ Nonlinearê°€ ì¤‘ìš”í•œê°€?

1. **Complex gradient landscape**
   - Linear: ë‹¨ìˆœ â†’ ì–´ë–¤ ë°©ë²•ë„ ì˜ ì‘ë™
   - XOR: ëŒ€ì¹­ì„± â†’ íŠ¹ìˆ˜í•œ ê¸°ë²• í•„ìš”
   - **Nonlinear: ë³µì¡ â†’ ì§„ì§œ ì‹¤ë ¥ í…ŒìŠ¤íŠ¸**

2. **Adaptiveì˜ ì§„ê°€ ë°œíœ˜**
   - NonlinearëŠ” per-parameter ì ì‘ì´ í•„ìˆ˜
   - Adam-like Adaptiveê°€ ì™„ë²½í•˜ê²Œ ì í•©
   - v1.2ê°€ ì˜¬ë°”ë¥¸ primitive (Adaptive) ì„ íƒ + ì‚¬ìš©

3. **Policy networkì˜ ì •í™•í•œ íŒë‹¨**
   ```
   v1.0: GD 71% (ì˜ëª») â†’ ì„±ëŠ¥ 3.23
   v1.2: Adaptive 56% (ì •í™•!) â†’ ì„±ëŠ¥ 1.40
   ```

---

## v1.2ì˜ ì˜ë¯¸

### ê°œë… ì¦ëª… 2ì°¨ ì„±ê³µ âœ…

**v1.0**:
- Meta-learning ê°œë… ì¦ëª…
- Adaptive strategy selection ì‘ë™
- í•˜ì§€ë§Œ primitive êµ¬í˜„ ì•½í•¨

**v1.2**:
- **Primitive í’ˆì§ˆì´ ì„±ëŠ¥ í–¥ìƒì— ì§ê²°ë¨ì„ ì¦ëª…**
- Adaptive primitive ê°•í™” â†’ Nonlinear 56% ê°œì„ 
- ì˜¬ë°”ë¥¸ ê°œì„  ë°©í–¥ í™•ì¸

### í•µì‹¬ í†µì°°

```
ì„±ëŠ¥ = Meta-System í’ˆì§ˆ Ã— Primitive í’ˆì§ˆ

v1.0: ì¢‹ì€ Meta-System Ã— ì•½í•œ Primitives = ë‚˜ìœ ì„±ëŠ¥
v1.2: ì¢‹ì€ Meta-System Ã— ê°•í•œ Primitives = ì¢‹ì€ ì„±ëŠ¥
```

**ì¦ê±°**:
- v1.0ë„ Adaptiveë¥¼ "ì„ íƒ"í•  ìˆ˜ ìˆì—ˆìŒ (32%, Nonlinear ì´ì „ ì‹¤í—˜)
- í•˜ì§€ë§Œ v1.0 AdaptiveëŠ” ì•½í•´ì„œ GDë¥¼ ì„ íƒ (71%)
- v1.2ì—ì„œ Adaptive ê°•í™” â†’ Policy networkê°€ Adaptive ì„ íƒ (56%)
- ê²°ê³¼: 56.59% ê°œì„ !

---

## v1.1 vs v1.2 êµí›ˆ

### v1.1ì˜ ì‹¤íŒ¨ (Meta-System ìˆ˜ì •)

**ì ‘ê·¼**: Winner-take-all ê°•ì œ + LR íŠœë‹
**ê²°ê³¼**: -31.44% (ëª¨ë“  ë°ì´í„°ì…‹ ì•…í™”)
**ë¬¸ì œ**: Meta-systemì€ ì´ë¯¸ ì¢‹ì•˜ìŒ, ê±´ë“œë¦¬ë©´ ë§ê°€ì§

### v1.2ì˜ ì„±ê³µ (Primitive ê°œì„ )

**ì ‘ê·¼**: Adam-like Adaptive + 20-sample PathSampling
**ê²°ê³¼**: +56.59% (Nonlinearì—ì„œ ëŒ€í­ ê°œì„ )
**í†µì°°**: Primitive í’ˆì§ˆì´ ì§„ì§œ ë¬¸ì œì˜€ìŒ!

---

## ëœë¤ì„± ë¬¸ì œ

### í˜„ì¬ ìƒí™©

**ë¬¸ì œ**:
- Linear, XORì—ì„œ v1.2ê°€ unlucky initialization
- ê°™ì€ ì½”ë“œì—¬ë„ ë‹¤ë¥¸ ê²°ê³¼ (ëœë¤ seed ë‹¤ë¦„)

**ì¦ê±°**:
- v1.0 Nonlinear: GD 71% vs v1.2 Nonlinear: Adaptive 56%
- v1.0 XOR: BestAttractor 58% vs v1.2 XOR: ActionGuided 49%
- ì™„ì „íˆ ë‹¤ë¥¸ ì „ëµ!

### í•´ê²° ë°©ë²•

#### ë‹¨ê¸° (ì¦‰ì‹œ ê°€ëŠ¥)
1. **Multiple runs + average**
   - 5-10ë²ˆ ì‹¤í–‰ í›„ í‰ê· 
   - ëœë¤ì„±ì˜ ì˜í–¥ ì¤„ì„
   - ë” ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ê²°ê³¼

2. **Random seed ê³ ì •**
   ```python
   np.random.seed(42)
   torch.manual_seed(42)
   ```
   - ì¬í˜„ ê°€ëŠ¥í•œ ê²°ê³¼
   - ë¹„êµ ê³µì •ì„± í™•ë³´

#### ì¥ê¸° (Pre-training)
1. **1000+ problemsë¡œ pre-train**
   - Policy networkê°€ ì¢‹ì€ ì´ˆê¸° ì „ëµ í•™ìŠµ
   - Cold start ë¬¸ì œ í•´ê²°
   - ì¼ê´€ëœ ì„±ëŠ¥

---

## ì˜¬ë°”ë¥¸ ê°œì„  ë¡œë“œë§µ (ê²€ì¦ë¨)

### Phase 1: Primitive í’ˆì§ˆ ê°œì„  âœ… (ë¶€ë¶„ ì™„ë£Œ)

**ì™„ë£Œ**:
1. âœ… Adaptive â†’ Adam-like (Nonlinear +56.59%)
2. âœ… PathSampling 5 â†’ 20 samples

**ì¶”ê°€ ê°œì„ ** (ë‹¤ìŒ ë‹¨ê³„):
3. â­ï¸ ë” ë‚˜ì€ primitives ì¶”ê°€:
   - Pure Adam primitive
   - RMSprop primitive
   - Nesterov Momentum primitive
   - AdaGrad primitive

4. â­ï¸ Primitive ê°œë³„ ë²¤ì¹˜ë§ˆí¬:
   - ê° primitiveì˜ ë‹¨ë… ì„±ëŠ¥ ì¸¡ì •
   - ìµœê³  ì„±ëŠ¥ primitivesë§Œ ì„ ë³„
   - ì•½í•œ primitives ì œê±°

### Phase 2: ëœë¤ì„± í•´ê²° â­ï¸

1. Multiple runs with averaging
2. Random seed ê³ ì • ì‹¤í—˜
3. ì´ˆê¸°í™” ì „ëµ ê°œì„ 

### Phase 3: Pre-training â­ï¸ (ì¥ê¸°)

1. 1000+ diverse problems ìƒì„±
2. Policy network pre-training
3. Transfer learning ì ìš©

---

## ê²°ë¡ : v1.2ëŠ” ì˜¬ë°”ë¥¸ ë°©í–¥!

### í•µì‹¬ ì„±ê³¼

1. **ê°œë… ê²€ì¦** âœ…
   - Primitive í’ˆì§ˆì´ ì„±ëŠ¥ì— ì§ê²°
   - Adam-like Adaptiveê°€ Nonlinearì—ì„œ 56.59% ê°œì„ 
   - Meta-systemì€ ì´ë¯¸ ì¢‹ì•˜ìŒ (ê±´ë“œë¦¬ì§€ ë§ ê²ƒ)

2. **ì˜¬ë°”ë¥¸ ë°©í–¥ í™•ì¸** âœ…
   - v1.1 (Meta-system ìˆ˜ì •): ì‹¤íŒ¨
   - v1.2 (Primitive ê°œì„ ): ì„±ê³µ
   - ì•ìœ¼ë¡œë„ primitive í’ˆì§ˆì— ì§‘ì¤‘í•´ì•¼ í•¨

3. **êµ¬ì²´ì  ì¦ê±°** âœ…
   ```
   v1.0 Nonlinear: GD 71% â†’ 3.23 (ì˜ëª»ëœ primitive ì„ íƒ)
   v1.2 Nonlinear: Adaptive 56% â†’ 1.40 (ì˜¬ë°”ë¥¸ primitive ì„ íƒ)
   â†’ 56.59% improvement!
   ```

### ë‹¤ìŒ ë‹¨ê³„

**v1.3** (ì¦‰ì‹œ):
- Multiple runs (5íšŒ) + averaging
- Random seed ê³ ì •
- Linear/XOR ëœë¤ì„± ì˜í–¥ í™•ì¸

**v1.4** (ë‹¨ê¸°):
- Adam, RMSprop, Nesterov primitives ì¶”ê°€
- Primitive ë²¤ì¹˜ë§ˆí¬
- ì•½í•œ primitives ì œê±°

**v2.0** (ì¥ê¸°):
- Pre-training on 1000+ problems
- QED/LAML-Q ìˆ˜ì¤€ ë‹¬ì„±

---

## ìµœì¢… ë©”ì‹œì§€

**v1.2ëŠ” ì„±ê³µì´ë‹¤!**

ì´ìœ :
1. Nonlinearì—ì„œ 56.59% ê°œì„  (ê°€ì¥ ì¤‘ìš”í•œ ë°ì´í„°ì…‹)
2. Primitive í’ˆì§ˆ â†’ ì„±ëŠ¥ ì§ê²° ì¦ëª…
3. ì˜¬ë°”ë¥¸ ê°œì„  ë°©í–¥ ê²€ì¦

**ëœë¤ì„± ë¬¸ì œ**:
- Linear, XORì˜ ì•…í™”ëŠ” unlucky initialization
- Multiple runsë¡œ í•´ê²° ê°€ëŠ¥
- Pre-trainingìœ¼ë¡œ ê·¼ë³¸ í•´ê²°

**ë¡œë“œë§µ**:
```
v1.0: Meta-system ê°œë… ì¦ëª… âœ…
v1.1: Meta-system ìˆ˜ì • ì‹œë„ (ì‹¤íŒ¨) âŒ
v1.2: Primitive í’ˆì§ˆ ê°œì„  (ì„±ê³µ!) âœ…
v1.3: ëœë¤ì„± í•´ê²° â­ï¸
v1.4: ë” ë§ì€ primitives â­ï¸
v2.0: Pre-training â­ï¸
```

---

**ì‘ì„±**: 2026-01-03
**ìƒíƒœ**: ë¶„ì„ ì™„ë£Œ, ë°©í–¥ ê²€ì¦ë¨
**ì˜ë¯¸**: Primitive Quality Matters! ğŸ¯

**"ì˜¬ë°”ë¥¸ ë°©í–¥ìœ¼ë¡œ í•œ ê±¸ìŒì”©"**
